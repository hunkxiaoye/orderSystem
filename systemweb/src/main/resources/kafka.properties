#生产者配置
#brokers集群
p.bootstrap.servers=hadoop2.jwl.com:9092,hadoop3.jwl.com:9092,hadoop4.jwl.com:9092
#即所有副本都同步到数据时send方法才返回, 以此来完全判断数据是否发送成功, 理论上来讲数据不会丢失.
p.acks=all
# 发送失败重试次数
p.retries=2
#批处理条数：当多个记录被发送到同一个分区时，生产者会尝试将记录合并到更少的请求中。这有助于客户端和服务器的性能。
p.batch.size=16384
#批处理延迟时间上限：即1ms过后，不管是否达到批处理数，都直接发送一次请求
p.linger.ms=1
#自动提交周期
p.auto.commit.interval.ms=1000
#消费监听器容器并发数
concurrency=3
p.block.on.buffer.full=true

#消费者配置
c.bootstrap.servers=hadoop2.jwl.com:9092,hadoop3.jwl.com:9092,hadoop4.jwl.com:9092
#消费者群组ID，发布-订阅模式，即如果一个生产者，多个消费者都要消费，那么需要定义自己的群组，同一群组内的消费者只有一个能消费到消息
c.group.id=test_yp
#如果为true，消费者的偏移量将在后台定期提交。
c.enable.auto.commit=true
#如何设置为自动提交（enable.auto.commit=true），这里设置自动提交周期
c.auto.commit.interval.ms=1000
#在使用Kafka的组管理时，用于检测消费者故障的超时
c.session.timeout.ms=20000
c.request.timeout.ms=31000
#一次从kafka中poll出来的数据条数
#max.poll.records条数据需要在在session.timeout.ms这个时间内处理完
c.max.poll.records=1
#server发送到消费端的最小数据，若是不满足这个数值则会等待直到满足指定大小。默认为1表示立即接收。
c.fetch.min.bytes=1
#若是不满足fetch.min.bytes时，等待消费端请求的最长等待时间
fetch.wait.max.ms=1000

